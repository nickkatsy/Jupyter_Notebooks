{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15add9a-f007-4476-8a1e-695263daf3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "df = pd.read_csv(\"C:/ML/python/data/iran.csv\",delimiter=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d72bc-a4c9-48c1-a322-8274e4bafcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()\n",
    "df.isna().sum()\n",
    "df.dropna(inplace=True)\n",
    "df.duplicated().sum()\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df['label'].value_counts().plot(kind='pie',autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e13a0-76f9-403d-b747-9e794617a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Comments'] = df['Comments'].str.lower()\n",
    "import re\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    pattern = r'<.*?>'\n",
    "    text = re.sub(pattern,\"\",text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df['Comments'] = df['Comments'].apply(remove_html_tags)\n",
    "df['Comments'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672099e-f829-4860-9849-3d12d0238c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "PUNC = string.punctuation\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",PUNC))\n",
    "\n",
    "df['Comments'] = df['Comments'].apply(remove_punctuations)\n",
    "\n",
    "df['Comments'] = df['Comments'].str.replace(r'\\d', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7661513-a1f5-4f0a-baa9-ce6d0e17be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words(\"english\"))\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = [word for word in tokens if word.lower() not in sw]\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "df['Comments'] = df['Comments'].apply(remove_stopwords)\n",
    "df['Comments'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe91726-6186-41a3-9d6f-94db7a82756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemma_tokens = [lemma.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemma_tokens)\n",
    "\n",
    "\n",
    "df['Comments'] = df['Comments'].apply(lemmatization)\n",
    "df['Comments'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d7d4a-b63e-42a5-a554-e599106889cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(i for i in df['Comments'])\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wc = WordCloud(colormap=\"Set2\",collocations=False).generate(text)\n",
    "plt.imshow(wc,interpolation=\"gaussian\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6799c-b493-4a5e-ab86-3cd5e59a167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "most_frequent_words = FreqDist(blob.words)\n",
    "top_50_words = most_frequent_words.most_common(50)\n",
    "print(\"top 50 most common comments: \",top_50_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd43f73-f4d0-4688-a0ef-8f3a8cb01c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(text):\n",
    "    return TextBlob(text).polarity\n",
    "\n",
    "\n",
    "\n",
    "df['polarity'] = df['Comments'].apply(polarity)\n",
    "\n",
    "\n",
    "\n",
    "def sentiment(label):\n",
    "    if label <0:\n",
    "        return \"Negative\"\n",
    "    elif label == 0:\n",
    "        return \"Neutral\"\n",
    "    elif label >= 0:\n",
    "        return \"Positive\"\n",
    "\n",
    "\n",
    "df['sentiment'] = df['polarity'].apply(sentiment)\n",
    "\n",
    "df['sentiment'].value_counts().plot(kind='pie',autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9fe698-0057-4094-a639-5d9361bc2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Cats > Gats\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x=df['sentiment'],y=df['label'])\n",
    "plt.title(\"label vs sentiment of youtube comment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad3936-479d-4401-a649-a5af2a7b9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df['Comments']\n",
    "X = cv.fit_transform(X).toarray()\n",
    "y = df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.20,random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ms = MinMaxScaler()\n",
    "\n",
    "X_train = ms.fit_transform(X_train)\n",
    "X_test = ms.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "GNB = GaussianNB()\n",
    "MNB = MultinomialNB()\n",
    "BNB = BernoulliNB()\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "def model_(X_train,X_test,y_train,y_test,model):\n",
    "    model = model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test,pred)\n",
    "    clf_rpt = classification_report(y_test, pred)\n",
    "    print(f'{model.__class__.__name__}, --ACC-- {acc*100:.2f}%; --Classification Report-- {clf_rpt}')\n",
    "    return pred\n",
    "\n",
    "lr_pred = model_(X_train, X_test, y_train, y_test, lr)\n",
    "GNB_pred = model_(X_train, X_test, y_train, y_test,GNB)\n",
    "MNB_pred = model_(X_train, X_test, y_train, y_test, MNB)\n",
    "BNB_pred = model_(X_train, X_test, y_train, y_test, BNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958b1ba-63c8-459a-b407-2266f1ab12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Comments']\n",
    "y = df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.15,random_state=1)\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "max_length = 0\n",
    "for sequence in X_train:\n",
    "    sequence_length = len(sequence)\n",
    "    if sequence_length > max_length:\n",
    "        max_length = sequence_length\n",
    "\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172c046-e955-4045-837c-088a3091050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train,maxlen=max_length,padding='post')\n",
    "X_test = pad_sequences(X_test,maxlen=max_length,padding='post')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Bidirectional,Dropout,SpatialDropout1D\n",
    "\n",
    "RNN = Sequential()\n",
    "RNN.add(Embedding(input_dim=(len(word_index) + 1),output_dim=150,input_length=max_length))\n",
    "RNN.add(SpatialDropout1D(0.3))\n",
    "RNN.add(Bidirectional(LSTM(50,dropout=0.1,recurrent_dropout=0.1)))\n",
    "RNN.add(Dropout(0.2))\n",
    "RNN.add(Dense(100,activation='relu'))\n",
    "RNN.add(Dropout(0.1))\n",
    "RNN.add(Dense(2,activation='sigmoid'))\n",
    "RNN.summary()\n",
    "RNN.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = RNN.fit(X_train,y_train,batch_size=32,epochs=10,validation_split=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a922f-f245-41bc-aa7c-8ad9662c83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "pred = RNN.predict(X_test)\n",
    "roc = roc_auc_score(y_test,pred)\n",
    "print(f\"roc_auc score: {roc*100:.2f}\")\n",
    "\n",
    "#### This is dog shit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ebfba-5162-4d85-ba87-fc58fa2845a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Trash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
